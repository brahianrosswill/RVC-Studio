{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOo0WTwRTOBkKmVuHNgv7u0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/brahianrosswill/StudioRvC/blob/main/Talkingface4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gnOXuXavU1Gv"
      },
      "outputs": [],
      "source": [
        "!pip install -q torch>=2.0.1+cu116 torchvision>=0.15.2+cu116 torchaudio==2.0.2 torchtext>=0.14.1 torchdata>=0.5.1 --extra-index-url https://download.pytorch.org/whl/cu116 -U\n",
        "!git lfs install\n",
        "%cd /content\n",
        "!git clone https://huggingface.co/camenduru/pocketsphinx-20.04-t4 pocketsphinx\n",
        "%cd  /content/pocketsphinx\n",
        "!sudo cmake --build build --target install\n",
        "%cd /content\n",
        "!git clone https://huggingface.co/camenduru/one-shot-talking-face-20.04-t4 one-shot-talking-face\n",
        "%cd /content/one-shot-talking-face\n",
        "!pip install -r /content/one-shot-talking-face/requirements.txt\n",
        "!chmod 755 /content/one-shot-talking-face/OpenFace/FeatureExtraction\n",
        "!mkdir /content/train\n",
        "!apt install -qq libgtk2.0-0 jq -y\n",
        "!pip install -q imageio-ffmpeg gradio numpy==1.23.0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/camenduru/one-shot-talking-face-colab/raw/main/test/audio.wav -O /content/audio.wav\n",
        "!wget https://github.com/camenduru/one-shot-talking-face-colab/blob/main/test/image.png?raw=true -O /content/image.png"
      ],
      "metadata": {
        "id": "L9kDV4UzU_kT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import os, subprocess, torchaudio\n",
        "from PIL import Image\n",
        "\n",
        "block = gr.Blocks()\n",
        "\n",
        "def calculate(image_in, audio_in):\n",
        "    waveform, sample_rate = torchaudio.load(audio_in)\n",
        "    torchaudio.save(\"/content/audio.wav\", waveform, sample_rate, encoding=\"PCM_S\", bits_per_sample=16)\n",
        "    image = Image.open(image_in)\n",
        "    image.save(\"/content/image.png\")\n",
        "\n",
        "    pocketsphinx_run = subprocess.run(['pocketsphinx', '-phone_align', 'yes', 'single', '/content/audio.wav'], check=True, capture_output=True)\n",
        "    jq_run = subprocess.run(['jq', '[.w[]|{word: (.t | ascii_upcase | sub(\"<S>\"; \"sil\") | sub(\"<SIL>\"; \"sil\") | sub(\"\\\\\\(2\\\\\\)\"; \"\") | sub(\"\\\\\\(3\\\\\\)\"; \"\") | sub(\"\\\\\\(4\\\\\\)\"; \"\") | sub(\"\\\\\\[SPEECH\\\\\\]\"; \"SIL\") | sub(\"\\\\\\[NOISE\\\\\\]\"; \"SIL\")), phones: [.w[]|{ph: .t | sub(\"\\\\\\+SPN\\\\\\+\"; \"SIL\") | sub(\"\\\\\\+NSN\\\\\\+\"; \"SIL\"), bg: (.b*100)|floor, ed: (.b*100+.d*100)|floor}]}]'], input=pocketsphinx_run.stdout, capture_output=True)\n",
        "    with open(\"/content/test.json\", \"w\") as f:\n",
        "        f.write(jq_run.stdout.decode('utf-8').strip())\n",
        "\n",
        "    os.system(f\"cd /content/one-shot-talking-face && python3 -B test_script.py --img_path /content/image.png --audio_path /content/audio.wav --phoneme_path /content/test.json --save_dir /content/train\")\n",
        "    return \"/content/train/image_audio.mp4\"\n",
        "\n",
        "with block:\n",
        "  gr.Markdown(\n",
        "  \"\"\"\n",
        "  <style> body { text-align: right} </style>\n",
        "  map: üìÑ [arxiv](https://arxiv.org/abs/2112.02749) &nbsp; ‚á® üë©‚Äçüíª [github](https://github.com/FuxiVirtualHuman/AAAI22-one-shot-talking-face) &nbsp; ‚á® ü¶í [colab](https://github.com/camenduru/one-shot-talking-face-colab) &nbsp; ‚á® ü§ó [huggingface](https://huggingface.co/spaces/camenduru/one-shot-talking-face) &nbsp; | &nbsp; tools: üåÄ [duplicate this space](https://huggingface.co/spaces/camenduru/sandbox?duplicate=true) &nbsp; | üê¢ [tortoise tts](https://huggingface.co/spaces/mdnestor/tortoise) &nbsp; | üé® [text-to-image](https://huggingface.co/models?pipeline_tag=text-to-image&sort=downloads) &nbsp; | üê£ [twitter](https://twitter.com/camenduru) &nbsp;\n",
        "  \"\"\")\n",
        "  with gr.Group():\n",
        "    with gr.Box():\n",
        "      with gr.Row().style(equal_height=True):\n",
        "        image_in = gr.Image(show_label=False, type=\"filepath\")\n",
        "        audio_in = gr.Audio(show_label=False, type='filepath')\n",
        "        video_out = gr.Video(show_label=False)\n",
        "      with gr.Row().style(equal_height=True):\n",
        "        btn = gr.Button(\"Generate\")\n",
        "  btn.click(calculate, inputs=[image_in, audio_in], outputs=[video_out])\n",
        "  block.launch(debug=True)"
      ],
      "metadata": {
        "id": "rrTk2yDpVHCu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}